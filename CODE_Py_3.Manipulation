###############################################################
############### RESOURCES
https://developers.google.com/edu/python/introduction
https://docs.python.org/3/tutorial/index.html


###############################################################
####################### GETTING STARTED

# SLICING
# BOOLEAN INDEXING
# APPLY
# IMPUTE MISSING
# PIVOT TABLE
# CROSSTAB
# MERGING DATAFRAMES
# SORTING DATAFRAMES
# CUT FUNCTION FOR BINNING
# ONE HOT ENCODING

###################### SLICING

# SLICING
# Get the ith row
data[i]
# Get the column named 'Fare'
data['Fare']
# Get the first 3 entries
data[:3]



word = 'Python'

word[0]
'p'

word[-1]
'n'

word[1:4]
'yth'

word[ :2]
'Py'

word[-2: ]
'on'

word[ :2] + word[2:]
'Python'



###################### BOOLEAN INDEXING

# List all females who did not graduate and got a loan
data.loc[(data["Gender"]=="Female") & (data["Education"]=="Not Graduate") & (data["Loan_Status"]=="Y"), ["Gender","Education","Loan_Status"]]


###################### APPLY

#Create a new function:
def num_missing(x):
  return sum(x.isnull())

#Applying per column:
print "Missing values per column:"
print data.apply(num_missing, axis=0) #axis=0 defines that function is to be applied on each column
#Applying per row:
print "\nMissing values per row:"
print data.apply(num_missing, axis=1).head() #axis=1 defines that function is to be applied on each row




###################### IMPUTE MISSING

#First we import a function to determine the mode
from scipy.stats import mode
mode(data['Gender'])
mode(data['Gender']).mode[0]
#Impute the values:
data['Gender'].fillna(mode(data['Gender']).mode[0], inplace=True)
data['Married'].fillna(mode(data['Married']).mode[0], inplace=True)
data['Self_Employed'].fillna(mode(data['Self_Employed']).mode[0], inplace=True)
#Now check the #missing values again to confirm:
print data.apply(num_missing, axis=0)



###################### PIVOT TABLE

#Determine pivot table
impute_grps = data.pivot_table(values=["LoanAmount"], index=["Gender","Married","Self_Employed"], aggfunc=np.mean)
print impute_grps



###################### CROSS TAB

# NUMBERS
pd.crosstab(data["Credit_History"],data["Loan_Status"],margins=True)

# PERCENTS
def percConvert(ser):
    return ser/float(ser[-1])
    pd.crosstab(data["Credit_History"],data["Loan_Status"],margins=True).apply(percConvert, axis=1)



###################### MERGING

# Initial DF
prop_rates = pd.DataFrame([1000, 5000, 12000], index=['Rural','Semiurban','Urban'],columns=['rates'])
prop_rates
# Merge
data_merged = data.merge(right=prop_rates, how='inner',left_on='Property_Area',right_index=True, sort=False)
data_merged.pivot_table(values='Credit_History',index=['Property_Area','rates'], aggfunc=len)


###################### SORTING DF

data_sorted = data.sort_values(['ApplicantIncome','CoapplicantIncome'], ascending=False)
data_sorted[['ApplicantIncome','CoapplicantIncome']].head(10)


###################### BINNING

#Binning:
def binning(col, cut_points, labels=None):
  #Define min and max values:
  minval = col.min()
  maxval = col.max()
  #create list by adding min and max to cut_points
  break_points = [minval] + cut_points + [maxval]
  #if no labels provided, use default labels 0 ... (n-1)
  if not labels:
    labels = range(len(cut_points)+1)
  #Binning using cut function of pandas
  colBin = pd.cut(col,bins=break_points,labels=labels,include_lowest=True)
  return colBin

#Binning age:
cut_points = [90,140,190]
labels = ["low","medium","high","very high"]
data["LoanAmount_Bin"] = binning(data["LoanAmount"], cut_points, labels)
print pd.value_counts(data["LoanAmount_Bin"], sort=False)


###################### ONE HOT ENCODING
from keras.utils import to_categorical
data = pd.read_csv('basketball_data.csv')
predictors = data.drop(['shot_result'], axis = 1).as_matrix()
target = to_categorical(data.shot_results)
